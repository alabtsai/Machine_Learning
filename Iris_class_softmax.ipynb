{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(150, 4)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(iris.data))\n",
    "print(iris.data.shape)\n",
    "print((iris.data.ndim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(150, 4)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(iris['data']))\n",
    "print(iris['data'].shape)\n",
    "print((iris['data'].ndim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris[\"data\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris[\"data\"][:, (2, 3)]  # petal length, petal width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iris[\"target\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "y = (iris[\"target\"] == 2).astype(np.int)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.reshape(150,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.zeros((150,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.append(y, z, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(150):\n",
    "    if y[i,0]==0:\n",
    "        y[i,1]=1\n",
    "    if y[i,0]==1:\n",
    "        y[i,1]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   if label=0,1 -->   non-  Iris-Virginica\n",
    "###   if label=1,0 -->         Iris-Virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/larry/tensorflow_prac/env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "w = tf.get_variable(name='weights', shape=(2, 2), initializer=tf.random_normal_initializer(0, 0.01))\n",
    "b = tf.get_variable(name='bias', shape=(1, 2), initializer=tf.random_normal_initializer(0, 0.01) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.cast(X, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.matmul(X, w)+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.nn.sigmoid_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function\n",
    "# use cross entropy of softmax of logits as the loss function\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y, name='entropy')\n",
    "loss = tf.reduce_mean(entropy, name='loss') # computes the mean over all the examples in the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'entropy_1/Reshape_2:0' shape=(150,) dtype=float32>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training op\n",
    "# using gradient descent with learning rate of 0.01 to minimize loss\n",
    "learning_rate = 0.2\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6891715\n",
      "0.8316218\n",
      "0.57899237\n",
      "0.6811709\n",
      "0.58555275\n",
      "0.47048733\n",
      "0.4969041\n",
      "0.5061703\n",
      "0.43491393\n",
      "0.38300455\n",
      "0.39360163\n",
      "0.40120593\n",
      "0.3705157\n",
      "0.33079538\n",
      "0.32048044\n",
      "0.33074924\n",
      "0.3244508\n",
      "0.29918614\n",
      "0.28193882\n",
      "0.28289405\n",
      "0.28583962\n",
      "0.2770923\n",
      "0.2616878\n",
      "0.25304028\n",
      "0.2541453\n",
      "0.2544337\n",
      "0.24682193\n",
      "0.23716255\n",
      "0.23327644\n",
      "0.23383331\n",
      "0.23230462\n",
      "0.2265485\n",
      "0.22057651\n",
      "0.2182831\n",
      "0.21818608\n",
      "0.21620247\n",
      "0.21180013\n",
      "0.20808335\n",
      "0.20675072\n",
      "0.20608115\n",
      "0.20395878\n",
      "0.20074025\n",
      "0.19831516\n",
      "0.19728582\n",
      "0.19631915\n",
      "0.19432129\n",
      "0.19193867\n",
      "0.19031656\n",
      "0.18939866\n",
      "0.18824363\n",
      "0.18648583\n",
      "0.18472354\n",
      "0.18351807\n",
      "0.18260798\n",
      "0.18141302\n",
      "0.17991531\n",
      "0.17858024\n",
      "0.17759953\n",
      "0.1766709\n",
      "0.17551757\n",
      "0.17427096\n",
      "0.17320871\n",
      "0.17233117\n",
      "0.17140688\n",
      "0.17034641\n",
      "0.16930498\n",
      "0.1684107\n",
      "0.16758364\n",
      "0.16668957\n",
      "0.165742\n",
      "0.16485447\n",
      "0.16405699\n",
      "0.16326605\n",
      "0.16242643\n",
      "0.1615861\n",
      "0.16080602\n",
      "0.16006762\n",
      "0.15931444\n",
      "0.15854111\n",
      "0.15779118\n",
      "0.15708353\n",
      "0.15638842\n",
      "0.1556798\n",
      "0.15497276\n",
      "0.15429302\n",
      "0.15363637\n",
      "0.15298016\n",
      "0.15231991\n",
      "0.15167212\n",
      "0.15104564\n",
      "0.15042928\n",
      "0.14981212\n",
      "0.14919922\n",
      "0.14860097\n",
      "0.14801605\n",
      "0.1474355\n",
      "0.14685717\n",
      "0.14628746\n",
      "0.14572988\n",
      "0.14518002\n",
      "0.14463338\n",
      "0.14409204\n",
      "0.14355996\n",
      "0.14303651\n",
      "0.14251806\n",
      "0.14200383\n",
      "0.14149633\n",
      "0.14099674\n",
      "0.14050324\n",
      "0.14001408\n",
      "0.1395301\n",
      "0.13905278\n",
      "0.13858171\n",
      "0.1381154\n",
      "0.13765365\n",
      "0.13719736\n",
      "0.13674693\n",
      "0.1363015\n",
      "0.13586041\n",
      "0.13542405\n",
      "0.13499287\n",
      "0.1345666\n",
      "0.13414468\n",
      "0.13372703\n",
      "0.13331394\n",
      "0.13290554\n",
      "0.13250138\n",
      "0.13210124\n",
      "0.1317052\n",
      "0.13131347\n",
      "0.13092585\n",
      "0.13054207\n",
      "0.13016209\n",
      "0.12978603\n",
      "0.12941386\n",
      "0.12904541\n",
      "0.12868051\n",
      "0.12831922\n",
      "0.12796158\n",
      "0.12760746\n",
      "0.1272567\n",
      "0.12690935\n",
      "0.12656538\n",
      "0.12622474\n",
      "0.12588735\n",
      "0.1255531\n",
      "0.12522203\n",
      "0.12489412\n",
      "0.12456926\n",
      "0.1242474\n",
      "0.1239285\n",
      "0.12361258\n",
      "0.12329956\n",
      "0.12298939\n",
      "0.12268201\n",
      "0.12237742\n",
      "0.12207559\n",
      "0.121776454\n",
      "0.12147997\n",
      "0.12118613\n",
      "0.120894864\n",
      "0.120606184\n",
      "0.12032003\n",
      "0.120036356\n",
      "0.11975515\n",
      "0.119476356\n",
      "0.11919997\n",
      "0.11892594\n",
      "0.11865425\n",
      "0.11838486\n",
      "0.11811775\n",
      "0.117852874\n",
      "0.11759023\n",
      "0.11732976\n",
      "0.11707147\n",
      "0.1168153\n",
      "0.11656122\n",
      "0.116309255\n",
      "0.11605934\n",
      "0.11581146\n",
      "0.11556555\n",
      "0.11532166\n",
      "0.11507973\n",
      "0.11483972\n",
      "0.11460159\n",
      "0.114365414\n",
      "0.11413104\n",
      "0.113898546\n",
      "0.11366787\n",
      "0.113439\n",
      "0.1132119\n",
      "0.11298654\n",
      "0.11276296\n",
      "0.11254106\n",
      "0.112320885\n",
      "0.11210238\n",
      "0.11188554\n",
      "0.111670345\n",
      "0.11145677\n",
      "0.11124476\n",
      "0.11103438\n",
      "0.110825576\n",
      "0.11061831\n",
      "0.110412575\n",
      "0.11020837\n",
      "0.11000566\n",
      "0.10980442\n",
      "0.10960467\n",
      "0.10940637\n",
      "0.10920949\n",
      "0.10901404\n",
      "0.10882001\n",
      "0.10862736\n",
      "0.10843606\n",
      "0.10824617\n",
      "0.108057596\n",
      "0.10787037\n",
      "0.107684456\n",
      "0.10749986\n",
      "0.10731654\n",
      "0.10713451\n",
      "0.10695373\n",
      "0.10677424\n",
      "0.10659594\n",
      "0.10641892\n",
      "0.106243074\n",
      "0.10606847\n",
      "0.10589502\n",
      "0.10572277\n",
      "0.105551675\n",
      "0.105381764\n",
      "0.105212964\n",
      "0.10504531\n",
      "0.10487878\n",
      "0.104713336\n",
      "0.10454903\n",
      "0.10438581\n",
      "0.10422363\n",
      "0.10406258\n",
      "0.103902526\n",
      "0.10374355\n",
      "0.103585616\n",
      "0.10342869\n",
      "0.1032728\n",
      "0.10311792\n",
      "0.10296403\n",
      "0.102811135\n",
      "0.10265922\n",
      "0.10250827\n",
      "0.1023583\n",
      "0.102209285\n",
      "0.10206119\n",
      "0.10191405\n",
      "0.10176783\n",
      "0.10162254\n",
      "0.101478145\n",
      "0.10133466\n",
      "0.101192065\n",
      "0.10105033\n",
      "0.10090952\n",
      "0.10076958\n",
      "0.10063047\n",
      "0.10049225\n",
      "0.10035486\n",
      "0.100218296\n",
      "0.10008256\n",
      "0.09994769\n",
      "0.09981362\n",
      "0.09968036\n",
      "0.09954789\n",
      "0.09941623\n",
      "0.099285364\n",
      "0.09915527\n",
      "0.09902595\n",
      "0.0988974\n",
      "0.098769635\n",
      "0.09864261\n",
      "0.09851635\n",
      "0.0983908\n",
      "0.09826603\n",
      "0.09814195\n",
      "0.098018624\n",
      "0.09789602\n",
      "0.097774126\n",
      "0.09765293\n",
      "0.097532436\n",
      "0.09741264\n",
      "0.09729355\n",
      "0.097175114\n",
      "0.09705738\n",
      "0.09694032\n",
      "0.09682391\n",
      "0.096708186\n",
      "0.0965931\n",
      "0.09647867\n",
      "0.09636489\n",
      "0.09625176\n",
      "0.09613927\n",
      "0.0960274\n",
      "0.09591613\n",
      "0.095805526\n",
      "0.09569552\n",
      "0.09558613\n",
      "0.09547736\n",
      "0.095369145\n",
      "0.095261574\n",
      "0.09515457\n",
      "0.09504815\n",
      "0.09494234\n",
      "0.09483708\n",
      "0.09473242\n",
      "0.09462833\n",
      "0.09452476\n",
      "0.0944218\n",
      "0.09431937\n",
      "0.09421753\n",
      "0.09411622\n",
      "0.09401542\n",
      "0.093915224\n",
      "0.09381551\n",
      "0.09371636\n",
      "0.09361772\n",
      "0.093519606\n",
      "0.09342204\n",
      "0.09332495\n",
      "0.09322841\n",
      "0.09313235\n",
      "0.09303679\n",
      "0.09294177\n",
      "0.09284723\n",
      "0.09275317\n",
      "0.09265962\n",
      "0.09256655\n",
      "0.09247394\n",
      "0.09238184\n",
      "0.09229019\n",
      "0.09219903\n",
      "0.09210836\n",
      "0.092018135\n",
      "0.09192837\n",
      "0.09183907\n",
      "0.09175022\n",
      "0.09166185\n",
      "0.091573894\n",
      "0.09148639\n",
      "0.09139933\n",
      "0.09131273\n",
      "0.09122658\n",
      "0.09114083\n",
      "0.09105551\n",
      "0.09097063\n",
      "0.0908862\n",
      "0.09080217\n",
      "0.09071854\n",
      "0.09063534\n",
      "0.09055257\n",
      "0.0904702\n",
      "0.09038823\n",
      "0.090306684\n",
      "0.09022554\n",
      "0.09014475\n",
      "0.09006441\n",
      "0.08998446\n",
      "0.08990489\n",
      "0.08982571\n",
      "0.08974692\n",
      "0.0896685\n",
      "0.08959047\n",
      "0.08951281\n",
      "0.08943554\n",
      "0.089358635\n",
      "0.0892821\n",
      "0.089205936\n",
      "0.08913013\n",
      "0.08905471\n",
      "0.08897964\n",
      "0.08890495\n",
      "0.08883056\n",
      "0.08875659\n",
      "0.088682935\n",
      "0.08860963\n",
      "0.08853669\n",
      "0.088464074\n",
      "0.08839182\n",
      "0.08831989\n",
      "0.08824832\n",
      "0.08817707\n",
      "0.08810616\n",
      "0.0880356\n",
      "0.087965325\n",
      "0.08789541\n",
      "0.087825805\n",
      "0.08775654\n",
      "0.08768761\n",
      "0.08761898\n",
      "0.08755066\n",
      "0.087482646\n",
      "0.08741497\n",
      "0.08734759\n",
      "0.08728056\n",
      "0.0872138\n",
      "0.08714735\n",
      "0.08708121\n",
      "0.08701537\n",
      "0.08694982\n",
      "0.086884566\n",
      "0.08681963\n",
      "0.08675498\n",
      "0.08669062\n",
      "0.08662656\n",
      "0.08656275\n",
      "0.08649926\n",
      "0.08643608\n",
      "0.08637315\n",
      "0.08631052\n",
      "0.08624816\n",
      "0.086186096\n",
      "0.086124286\n",
      "0.08606277\n",
      "0.08600151\n",
      "0.08594052\n",
      "0.08587982\n",
      "0.08581936\n",
      "0.08575919\n",
      "0.08569929\n",
      "0.08563965\n",
      "0.08558025\n",
      "0.085521154\n",
      "0.08546228\n",
      "0.08540368\n",
      "0.085345335\n",
      "0.08528725\n",
      "0.08522942\n",
      "0.08517182\n",
      "0.085114494\n",
      "0.08505741\n",
      "0.08500057\n",
      "0.084943965\n",
      "0.08488762\n",
      "0.08483152\n",
      "0.08477567\n",
      "0.084720045\n",
      "0.08466466\n",
      "0.08460952\n",
      "0.084554605\n",
      "0.08449993\n",
      "0.0844455\n",
      "0.08439128\n",
      "0.0843373\n",
      "0.084283575\n",
      "0.08423006\n",
      "0.08417676\n",
      "0.0841237\n",
      "0.08407087\n",
      "0.084018245\n",
      "0.083965845\n",
      "0.08391369\n",
      "0.08386172\n",
      "0.083809994\n",
      "0.083758466\n",
      "0.08370717\n",
      "0.08365607\n",
      "0.08360521\n",
      "0.08355454\n",
      "0.08350409\n",
      "0.083453834\n",
      "0.083403826\n",
      "0.08335399\n",
      "0.08330435\n",
      "0.08325496\n",
      "0.083205745\n",
      "0.08315674\n",
      "0.08310794\n",
      "0.083059356\n",
      "0.08301092\n",
      "0.082962744\n",
      "0.08291474\n",
      "0.08286692\n",
      "0.082819305\n",
      "0.08277189\n",
      "0.08272465\n",
      "0.082677625\n",
      "0.08263078\n",
      "0.08258414\n",
      "0.082537666\n",
      "0.08249138\n",
      "0.082445316\n",
      "0.08239941\n",
      "0.082353696\n",
      "0.082308166\n",
      "0.0822628\n",
      "0.08221764\n",
      "0.08217266\n",
      "0.082127854\n",
      "0.08208323\n",
      "0.08203877\n",
      "0.08199451\n",
      "0.08195041\n",
      "0.08190651\n",
      "0.08186277\n",
      "0.081819184\n",
      "0.0817758\n",
      "0.08173257\n",
      "0.081689544\n",
      "0.08164665\n",
      "0.08160392\n",
      "0.081561394\n",
      "0.08151902\n",
      "0.08147682\n",
      "0.08143478\n",
      "0.08139289\n",
      "0.08135117\n",
      "0.08130962\n",
      "0.081268236\n",
      "0.08122702\n",
      "0.08118594\n",
      "0.081145056\n",
      "0.0811043\n",
      "0.08106371\n",
      "0.08102328\n",
      "0.08098301\n",
      "0.080942914\n",
      "0.080902934\n",
      "0.08086315\n",
      "0.08082348\n",
      "0.08078398\n",
      "0.08074463\n",
      "0.08070543\n",
      "0.08066639\n",
      "0.0806275\n",
      "0.08058875\n",
      "0.08055016\n",
      "0.080511704\n",
      "0.08047339\n",
      "0.08043524\n",
      "0.080397226\n",
      "0.08035935\n",
      "0.08032164\n",
      "0.08028405\n",
      "0.08024662\n",
      "0.08020934\n",
      "0.08017217\n",
      "0.08013519\n",
      "0.0800983\n",
      "0.08006158\n",
      "0.08002497\n",
      "0.07998851\n",
      "0.079952195\n",
      "0.07991601\n",
      "0.07987996\n",
      "0.07984406\n",
      "0.07980828\n",
      "0.07977264\n",
      "0.07973712\n",
      "0.07970175\n",
      "0.0796665\n",
      "0.079631396\n",
      "0.079596415\n",
      "0.079561554\n",
      "0.07952682\n",
      "0.07949223\n",
      "0.07945775\n",
      "0.07942343\n",
      "0.07938921\n",
      "0.07935513\n",
      "0.07932119\n",
      "0.079287335\n",
      "0.07925363\n",
      "0.07922005\n",
      "0.079186566\n",
      "0.07915324\n",
      "0.07912001\n",
      "0.07908694\n",
      "0.079053946\n",
      "0.07902111\n",
      "0.078988366\n",
      "0.07895574\n",
      "0.07892325\n",
      "0.07889089\n",
      "0.07885862\n",
      "0.07882649\n",
      "0.07879446\n",
      "0.07876253\n",
      "0.078730755\n",
      "0.07869908\n",
      "0.078667514\n",
      "0.07863606\n",
      "0.078604735\n",
      "0.0785735\n",
      "0.07854239\n",
      "0.078511395\n",
      "0.07848051\n",
      "0.07844973\n",
      "0.07841906\n",
      "0.07838853\n",
      "0.07835806\n",
      "0.07832772\n",
      "0.0782975\n",
      "0.0782674\n",
      "0.078237385\n",
      "0.07820747\n",
      "0.078177676\n",
      "0.07814798\n",
      "0.078118406\n",
      "0.0780889\n",
      "0.07805953\n",
      "0.078030236\n",
      "0.0780011\n",
      "0.07797202\n",
      "0.07794305\n",
      "0.07791418\n",
      "0.07788545\n",
      "0.07785678\n",
      "0.07782821\n",
      "0.07779975\n",
      "0.07777141\n",
      "0.077743165\n",
      "0.077714995\n",
      "0.077686936\n",
      "0.07765897\n",
      "0.07763111\n",
      "0.077603355\n",
      "0.07757567\n",
      "0.0775481\n",
      "0.07752063\n",
      "0.07749324\n",
      "0.07746596\n",
      "0.07743878\n",
      "0.07741169\n",
      "0.07738467\n",
      "0.07735777\n",
      "0.07733096\n",
      "0.07730425\n",
      "0.07727761\n",
      "0.07725107\n",
      "0.07722464\n",
      "0.07719828\n",
      "0.077172026\n",
      "0.07714585\n",
      "0.07711976\n",
      "0.07709376\n",
      "0.077067874\n",
      "0.077042066\n",
      "0.07701633\n",
      "0.0769907\n",
      "0.076965146\n",
      "0.07693969\n",
      "0.0769143\n",
      "0.076889016\n",
      "0.07686382\n",
      "0.07683871\n",
      "0.07681367\n",
      "0.07678872\n",
      "0.07676386\n",
      "0.07673909\n",
      "0.076714404\n",
      "0.07668979\n",
      "0.07666528\n",
      "0.07664083\n",
      "0.076616466\n",
      "0.0765922\n",
      "0.07656802\n",
      "0.0765439\n",
      "0.07651987\n",
      "0.076495916\n",
      "0.07647204\n",
      "0.07644826\n",
      "0.07642457\n",
      "0.07640092\n",
      "0.07637737\n",
      "0.076353915\n",
      "0.076330535\n",
      "0.076307185\n",
      "0.07628397\n",
      "0.07626083\n",
      "0.076237746\n",
      "0.07621474\n",
      "0.07619181\n",
      "0.07616895\n",
      "0.076146185\n",
      "0.07612349\n",
      "0.07610086\n",
      "0.07607832\n",
      "0.07605586\n",
      "0.076033466\n",
      "0.07601113\n",
      "0.075988896\n",
      "0.07596672\n",
      "0.07594461\n",
      "0.07592259\n",
      "0.07590062\n",
      "0.07587876\n",
      "0.07585694\n",
      "0.075835206\n",
      "0.07581355\n",
      "0.07579195\n",
      "0.07577042\n",
      "0.07574897\n",
      "0.075727604\n",
      "0.07570628\n"
     ]
    }
   ],
   "source": [
    "with  tf.Session()as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(700):\n",
    "        _,l=sess.run([optimizer, loss])\n",
    "        print(l)\n",
    "    weight_,bias_=sess.run([w,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.6424526 -1.6233788]\n",
      " [ 4.0063066 -4.0042067]]\n",
      "[[-14.559635  14.544092]]\n"
     ]
    }
   ],
   "source": [
    "print(weight_)\n",
    "print(bias_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(weight_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9994338e-01 5.6675148e-05]]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "ttimg=np.array([[7,2]])\n",
    "ttimg=tf.cast(ttimg,tf.float32)\n",
    "loog = tf.matmul(ttimg, weight_) + bias_ \n",
    "preds = tf.nn.softmax(loog)\n",
    "correct_preds = tf.argmax(preds, 1)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(preds))\n",
    "    print(sess.run(correct_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.0081974e-12 1.0000000e+00]]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "ttimg=np.array([[1,0]])\n",
    "ttimg=tf.cast(ttimg,tf.float32)\n",
    "loog = tf.matmul(ttimg, weight_) + bias_ \n",
    "preds = tf.nn.softmax(loog)\n",
    "correct_preds = tf.argmax(preds, 1)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(preds))\n",
    "    print(sess.run(correct_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
